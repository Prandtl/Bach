\documentclass[12pt]{report}
\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage{listings}

\textheight 24cm
\voffset -2cm
\textwidth 17cm
\hoffset -1.5cm
\topmargin 0mm

\renewcommand{\bottomfraction}{1.0}
  % Какая часть снизу листа может быть занята картинками
\renewcommand{\textfraction}{0.0}
  % Какая часть листа должна быть занята текстом

\newtheorem{theorem}{Теорема}
\newtheorem{definition}{Определение}
\newtheorem{ex}{Пример}
\newtheorem{tab}{Таблица}
\newtheorem{sat}{Утверждение}


\begin{document}
  \pagestyle{empty} % нумерация выкл.
  \begin{center}
    \small
    МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ ФЕДЕРАЦИИ\\
    Федеральное государственное автономное образовательное учреждение высшего образования\\
    УРАЛЬСКИЙ ФЕДЕРАЛЬНЫЙ УНИВЕРСИТЕТ \\
    имени первого Президента России Б.Н. Ельцина\\
    \vspace{1em}
    ИНСТИТУТ ЕСТЕСТВЕННЫХ НАУК И МАТЕМАТИКИ\\
    Департамент математики, механики и компьютерных наук
  \end{center}

  \vspace{1em}

  \begin{center}
    \large
    АДАПТАЦИЯ АЛГОРИТМА ПАРАЛЛЕЛЬНОГО\\ СТОХАСТИЧЕСКОГО ГРАДИЕНТНОГО СПУСКА К ЗАДАЧАМ\\ МЕХАНИКИ СПЛОШНОЙ СРЕДЫ
    \vspace{1em}

    \normalsize
    Направление подготовки 09.03.03 <<Прикладная информатика>>\\
    \vspace{1em}
    Образовательная программа <<Прикладная информатика в информационной сфере>>
    \end{center}
  \vspace{1em}

  \begin{tabular}[t]{@{}l}
    Допустить к защите:\\
    Директор департамента:\\ к.ф.-м.н., доц. М. О. Асанов\\
    \underline{\hspace{5cm}}\\
  \end{tabular}
  \hfill
  \begin{tabular}[t]{l@{}}
      Выпускная квалификационная\\работа бакалавра\\
      \textbf{Учанева}\\
      \textbf{Василия Вячеславовича}\\
      \underline{\hspace{5cm}}\\
      \vspace{1em}\\
      Научный руководитель:\\ к.ф.-м.н. В. С. Зверев\\
      \underline{\hspace{5cm}}\\
  \end{tabular}

  \vspace*{\fill}
  \begin{center}
    Екатеринбург 2017 г.
  \end{center}

  \newpage
  \pagestyle{plain} % нумерация вкл.
  \chapter*{Реферат}
  Учанев В. В. - -//- -: стр. - -,

  Ключевые слова: СТОХАСТИЧЕСКИЙ ГРАДИЕНТНЫЙ СПУСК, ПАРАЛЛЕЛИЗАЦИЯ.

  В данной работе рассматривается...{TODO:text}

  \newpage
  \tableofcontents

  \chapter*{Введение}
  \addcontentsline{toc}{chapter}{Введение}
  Оптимизация - поиск наилучшего элемента согласно некоторому критерию,
  например поиск максимального или минимального элемента. Для функции одной
  переменной существует аналитический метод поиска точек экстремума,
  но для функций двух и более переменных используются численные методы.

  Не смотря на то, что математические основы оптимизации были заложены
  в XVIII-XIX веке, широко использоваться они начали во второй половине XX века,
  в связи с появлением и распространением ЭВМ, поскольку использование
  методов оптимизации требует в большинстве случаев большой вычислительной работы.
  Поиск минимального/максимального значения используется во множестве областей:
  в экономике для оптимизации процессов и максимизации прибыли,
  в механике для проектирования и расчетов,
  в социальных науках для моделирования и оптимизации общественных процессов.

  За последние несколько лет был довольно большой скачок в развитии методов
  оптимизации, связанный c развитием машинного обучения. Методы оптимизации
  используются на этапе обучения: параметры модели подбираются так,
  чтобы уменьшить ошибку относительно тренировочного набора данных.

  Одним из наиболее используемых в машинном обучение алгоритмов является
  алгоритм градиентного спуска и его модификации. Причины этому в простоте его
  реализации и скорости работы, которая важна, так как во время обучения
  модель проходит через множество итераций и чем быстрее будет проходить
  каждая итерация, тем быстрее будет процесс поиска оптимальных параметров
  аппроксимирующей модели, то есть обучение.

  \chapter{Постановка задачи}
  {TODO}

  \chapter{Градиентный спуск}
  \section{Градиентный спуск}

  Градиентный спуск - метод нахождения локального экстремума функции с помощью
  движения по направлению градиента/антиградиента. Это наиболее простой
  в реализации метод среди всех методов локальной оптимизации. Зачастую
  используется как часть других методов оптимизации. Этот метод не решает задачу
  поиска глобального минимума/максимума, то есть нужны модификации для поиска
  глобального экстремума.

  Если нам дана функция $F(x)$ и необходимо найти ее минимум, то шаг градиентного
  спуска выглядит следующим образом:
  \begin{equation} \label{eq:gradient_descent_step}
    x^{j+1}=x^j- \lambda \nabla F(x^j)
  \end{equation}
  где $x^j$- приближение минимума функции на $j$-ом шаге, а $\lambda$ - шаг
  градиентного спуска, который может быть постоянной величиной или вычисляться
  на каждом шаге, например делением каждый раз на некое число, что увеличивает
  вероятность того, что алгоритм сойдется.
  Рассмотрим алгоритм градиентного спуска:
  \begin{enumerate}
    \item
    Задается начальное приближение: $x^0$ и необходимая точность расчета: $\alpha$.
    \item
    Рассчитывается по формуле~\ref{eq:gradient_descent_step} следующее приближение $x^{j+1}$.
    \item
    Проверяются условия остановки, например:
    \begin{enumerate}
      \item
      $|x^{j+1}-x^j| < \alpha$.
      \item
      $\exists i: x_i < x_{i_{min}}$ или $x_i > x_{i_{max}}$, где $x_{i_{min}}$ и $x_{i_{max}}$
      заранее заданые границы для координаты $x_i$.
      \item
      $j>j_{max}$, где $j_{max}$ - заранее заданное максимальное число итераций.
    \end{enumerate}
    Если условие остановки выполняется завершаем алгоритм, полученоу $x^j$ - наше найденое решение.
  \end{enumerate}

  \section{Проблемы алгоритма градиентного спуска}
  Градиентный спуск позволяет находить оптимальное решение в простых случаях, но
  в сложных задачах становятся видны следующие проблемы:
  \begin{enumerate}
    \item
    Для оптимальной работы алгоритма выжен правильно выбраный коэффициент $\lambda$
    - величина шага градиетного спуска. При слишком маленьком шаге алгоритм
    сходится слишком долго и может застрять в локальном минимуме, а при слишком
    большом шаге алгоритм будет перескакивать через решение и может расходиться.
    Возможным решением является, например, использование изменяющихся со временем
    значений для шага (т.н. Learning schedules). Но подобное решение будет
    сильно зависеть от данных и его придется адаптировать в каждом конкретном случае.
    \item
    Градиентный спуск застревает в локальных минимумах и в седловых точках.
    При этом седловые точки являются даже большей проблемой, так как чем больше
    размерность пространства в котором мы работаем, тем выше вероятность
    появления седловых точек.
    \item
    Градиентный спуск не оптимизирован для прохождения по оврагам - областям, где
    изменения по одной из компонент намного более крутые чем по другим.
    Градиентный спуск скачет с одной стороны оврага на другую, продвигаясь при
    этом на очень малое расстояние в сторону минимума.
  \end{enumerate}
  Чтобы решить эти проблемы градиентного спуска используются различные модификации,
  некоторые из которых мы рассмотрим далее.

  \section{Стохастический градиентный спуск}
    В стохастическом градиентном спуске, градиент функции в приближенном решении
    аппроксимируется градиентом по одной из компонент, тогда шаг градиентного
    спуска выглядит следующим образом:
    \begin{equation}
      x^{j+1}=x^j- \lambda \nabla F(x^j_i)
    \end{equation}

    Если обычный градиентный спуск на каждом шаге считает градиент полностью, то
    стохасическому градиентному спуску требуется всего одна операция на каждом
    шаге, что значительно увеличивает скорость вычисления на каждом шаге. При
    этом значительно уменьшается точность и функция остановки начинает сильно
    флуктуировать. {TODO: add image}

    Интересной особенностью стохастического градиентного спуска является то, что
    за счет флуктуаций решения, алгоритм способен выходить из локальных минимумов
    и находить решение лучшее, чем обычный градиентный спуск. Проблемой этого
    метода является то, что эти же флуктуации мешают алгоритму попасть в искомую
    точку минимума, поскольку алгоритм постоянно перескакивает через нее.

  \section{Mini-batch gradient descent}
    Этот метод позволяет получить нечто среднее между обычным градиентным спуском
    и стохастическим градиентным спуском. Градиент в точке аппроксимируется
    градиентом по некоторому небольшому количеству компонент. За счет этого мы
    увеличиваем скорость по сравнению с обычным градиетным спуском, а также получаем
    способность выходить из локальных маинимумов, но при этом также уменьшаем
    флуктуации по сравнению со стохастическим градиентным спуском. При использовании
    современных библиотек для матричных операций, скорость обработки каждого
    шага может достигать скорости  работы стохастического градиентного спуска,
    за счет использования векторных расширений процессора.

  \section{Градиентный спуск с импульсом и ускоренный градиентный спуск Нестерова}
    Этот метод заключается в накоплении импульса на каждом шаге. Использование
    импульса позволяет двигаться более уверенно в нужном направлении и уменьшить
    величину осциляций. Формула для шага градиентного спуска изменяется следующим
    образом:
    \begin{equation}
      v^{j} = \mu v^{j-1} + \lambda \nabla F(x^j)
    \end{equation}
    \begin{equation}
      x^{j+1} = x^j- v^j
    \end{equation}

    $v^j$ - скользящее среднее шага градиентного спуска, которое позволяет нам
    учитывать шаги сделанные на предыдущих итерациях. $\mu$ здесь - это коэффициент
    сохранения, который отвечает за то, насколько сильно история будет влиять на
    новый шаг. $\mu$ берется из интервала $(0;1)$ и обычно равен примерно $0.9$.
    Градиентный спуск с импульсом лучше проходит через овраги, быстрее продвигается
    по плато, а так же способен выходить из локальных минимумов и седловых точек.

    {TODO: images}

    Ускоренный градиент Нестерова использует следущую идею из вычислительной
    математики: заглядывание вперед по вектору градиента. Вместо того чтобы считать
    градиент функции $F$ в точке $x^j$, посчитаем градиент в точке $x^j - \mu v^{j-1}$

    \begin{equation}
      v^{j} = \mu v^{j-1} + \lambda \nabla F(x^j - \mu v^{j-1})
    \end{equation}
    \begin{equation}
      x^{j+1} = x^j- v^j
    \end{equation}

    Подобное изменение позволяет, алгоритму изменять $v$ быстрее и более отзывчиво,
    позволяя работать стабильнее чем в обычной реализации градиентного спуска с
    импульсом, а особенно для больших значений $\mu$. Но при этом следует понимать,
    что не во всех случаях ускоренный градиент Нестерова будет работать быстрее.

  \section{Adagrad}
    Adagrad - алгоритм оптимизации основаный на градиентном спуске, идея которого
    в следующем: некоторые компоненты вектора $x$ обновляются сильно, а другие -
    нет, изменим формулу для шага градиентного спуска таким образом, чтобы шаг по
    компонентам производная в которых большая, шаг становился меньше, чем по тем,
    в которых производная близка нулю. Для этого будем хранить сумму квадратов
    обновлений.

    Рассмотрим как выглядит шаг Adagrad. Введем для удобства следующее обозначение:
    $g^j$ - градиент на $j$-ом шаге:
    $$g^j=\nabla F(x^j)$$
    Тогда формула обновления будет выглядеть следующим образом:
    \begin{equation}
      G^j = G^{j-1} + g^j \circ g^j
    \end{equation}
    \begin{equation}
      x^{j+1} = x^j - \frac{\lambda}{\sqrt{G^j+\varepsilon}} \circ g^j
    \end{equation}

    Здесь $\circ$ - это операция поэлементного умножения, а $\varepsilon$ - параметр
    необходимый, чтобы избежать деления на $0$. Порядок $\varepsilon$ обычно равен
    $10^{-6}$. При этом Adagrad может выглядеть и иначе, общая идея - использование
    чего-то, уменьшающего величину шага, для компонент производная в которых большая.

    Достоинством Adagrad является отсутствие необходимости выбирать коэффициент
    $\lambda$, достаточно выбрать его достаточно большим, чтобы алгоритм работал
    и достаточно маленьким, чтобы он не стал расходиться. За счет того что $G^j$
    постоянно растет - мы получаем постепенное затухание величины шага, в чем
    собственно кроется недостаток Adagrad: через некоторое время шаг обновления
    становится настолько маленьким, что наступает паралич алгоритма.

  \section{RMSProp и Adadelta}
    RMSProp и Adadelta - два метода призваные решить проблему с затуханием
    Adadelta. Модифицируем шаг для Adadelta следующим образом: вместо хранения
    суммы квадратов обновлений, будем использовать экспоненциально затухающее
    бегущее среднее. Пусть $E[g^2]^j$ - бегущее среднее на j-ом шаге, тогда:
    \begin{equation}
      E[g^2]^j=\mu E[g^2]^{j-1} + (1 - \mu)g^j \circ g^j
    \end{equation}

    RMSProp - root mean square propagation, берет свое название из того, что
    знаменатель будет корнем из среднего квадратов градиента:
    \begin{equation}
      RMS[g]^j = \sqrt{E[g^2]^j + \varepsilon}
    \end{equation}

    \begin{equation} \label{eq:rms_step}
      x^{j+1} = x^j - \frac{\lambda}{RMS[g]^j} \circ g^j
    \end{equation}

    Adadelta добавляет в числитель в~\ref{eq:rms_step} стабилизирующий член,
    пропорциональный $RMS[\Delta x^j]$, чтобы понять зачем они это делают
    рассмотрим $\Delta x$ в~\ref{eq:rms_step}:
    \begin{equation} \label{eq:rms_step_delta}
      \Delta x = \frac{\lambda}{RMS[g]^j} \circ g^j
    \end{equation}
    Заметим что размерности $x$ и $\Delta x$ должны совпадать, а $\Delta x$
    в~\ref{eq:rms_step_delta} - безразмерная величина. Поэтому изменим шаг градиентного
    спуска следующим образом:

    \begin{equation}
      \Delta x = \frac{RMS[\Delta x]^{j-1}}{RMS[g]^j} \circ g^j
    \end{equation}
    \begin{equation}
      x^{j+1} = x^j - \Delta x
    \end{equation}
    \begin{equation}
      E[\Delta x^2]^j = \mu E[\Delta x^2]^{j-1} + (1 - \mu)\Delta x^2
    \end{equation}
    \begin{equation}
      RMS[\Delta x]^j = \sqrt{E[\Delta x^2]^j + \varepsilon }
    \end{equation}

    Заметим следующее коэффициент $\lambda$ - исчез, но теперь появился новый
    параметр: $RMS[\Delta x]^{-1}$ - который необходим для первого шага. Если
    это значение будет близко к нулю, то мы получим на первых шагах поведение
    противоположное Adagrad: мы будем делать большие шаги по компонентам, значение
    производной в которых большое.

  \section{ADAM}
    ADAM - adaptive moment estimation - ещё один метод оптимизации, сочетающий
    идею накопления движения и идею меньших шагов по компонентам с большой
    производной. Здесь мы используем бегущее среднее значений градиента и бегущее
    среднее квадратов градиента, чтобы иметь оценку того как градиент изменяется:
    \begin{equation}
      m^j = \beta_1 m^{j-1} + (1 - \beta_1)g^j
    \end{equation}
    \begin{equation}
      v^j = \beta_2 v^{j-1} + (1 - \beta_2)g^j \circ g^j
    \end{equation}

    Чтобы избавиться от еще одной пары параметров в лице $m^0$ и $v^0$, поэтому
    мы будем использовать не сами $m^j$ и $v^j$, а $\hat{m}^j$ и $\hat{v}^j$,
    которые будут искуственно увеличивать $m$ и $v$ на первых шагах.

    \begin{equation}
      \hat{m}^j = \frac{m^j}{1-\beta_1^j}
    \end{equation}
    \begin{equation}
      \hat{v}^j = \frac{v^j}{1-\beta_2^j}
    \end{equation}

    Итоговое правило обновления примет следующий вид:

    \begin{equation}
      x^{j+1} = x^j - \frac{\lambda}{\hat{v}^j + \varepsilon} \circ \hat{m}^j
    \end{equation}

    Авторы алгоритма предлагают следующие значения по умолчанию: $\beta_1 = 0.9$,
    $\beta_2 = 0.999$, $\varepsilon = 10^{-8}$ и утверждают, что алгоритм выступает
    лучше или примерно так же как и все предыдущие алгоритмы за счет начальной
    калибровки.

  \section{Сравнение алгоритмов оптимизации?}

  \chapter{Реализация градиентного спуска на Python}
  Рассмотрим реализацию градиентного спуска на языке Python, с использованием
  библиотеки numpy.

  Шаг градиентного спуска будет выглядеть следующим образом:

  \begin{lstlisting}[language=Python, frame=single]
    def gradient_descent_step(old, lambd):
      new = old - get_gradient(old)*lambd
      return new
  \end{lstlisting}

  Этот метод принимает массив \verb|old| - точку в которой мы находимся и
  \verb|lambd| - параметр который отвечает за величину шага. Здесь и далее метод
  \verb|get_gradient| - метод который позволяет найти значение градиента в точке.

  Используя эту реализацию шага градиентного спуска мы получаем следующую
  реализацию самого градиентного спуска:

  \begin{lstlisting}[language=Python, frame=single]
    x = np.arange(-2, 2, 0.1)
    y = np.arange(-2, 2, 0.1)
    xx, yy = np.meshgrid(x, y)
    xravel = np.ravel(xx)
    yravel = np.ravel(yy)
    points = list(zip(xravel, yravel))
    f, g, a = getTestData(1e-10)
    z = np.array([ f(point) for point in points ])
    zz = z.reshape(xx.shape)
    h = plt.contour(xx, yy, zz, 40)
    old = [1,1]
    delta = 1
    while delta>1e-5:
      new = gradient_descent_step(old, 0.001)
      plt.plot([old[0], new[0]], [old[1], new[1]], 'r-', lw=1)
      old = new
      delta = old - new
  \end{lstlisting}

  Чтобы нарисовать график функции и путь по которму пойдет градиентный спуск
  нужно получить двухмерный массив точек, с которым мы будем оперировать. Метод
  \verb|np.arange(a, b, h)| возвращает вектор элементов от \verb|a| до \verb|b|,
  \verb|с| шагом \verb|h|. Затем метод \verb|np.meshgrid(x, y)| возвращает две
  матрицы \verb|xx, yy|. Строки \verb|xx|, равны вектору \verb|x|, количество
  этих строк равно длине вектора \verb|y|, матрица \verb|yy| получается подобным
  образом. Метод \verb|np.ravel(xx)| преобразовывает матрицу обратно в вектор,
  подставляя друг за другом строки матрицы \verb|xx|. \verb|list(zip(xravel, yravel))|
  возвращает список пар элементов \verb|xravel| и \verb|yravel|. В итоге,
  например если \verb|x = [0, 0.1, … , 1]| и \verb|y = [-1, -0.9, … , 1]|, то
  \verb|points| будет равно
  \begin{center}
    \begin{verbatim}
      [(-1, 0), (-1, 0.1), … ,(-1, 1),
      (-0.9, 0), (-0.9, 0.1), …(-0.9, 1),
      …,
      (1, 0), (1, 0.1), … ,(1, 1)].
    \end{verbatim}
  \end{center}
	Метод \verb|getTestData| возвращает тестовую функцию, а так же функцию для
  получения градиента и антиградиента. Зная нашу тестовую функцию и имея список
  точек можно найти значение функции в каждой точке:
  \verb|np.array([ f(point) for point in points ])|, далее, для удобства, этот
  массив мы преобразуем в матрицу с размерами матрицы \verb|xx|. Далее происходит
  иницализация параметров и мы попадаем в основной цикл: алгоритм будет двигаться
  по градиенту пока величина шага не станет значительно мала, отрисовывая на
  каждом шаге пройденное расстояние.

  Далее будут рассмотрены реализации шага градиентного спуска для разных модификаций,
  реализация градиентного спуска рассматриваться не будет, так как отличается
  лишь в деталях: изменяется количество параметров, которые необходимо
  инициализировать и передать в функцию, совершающую шаг градиентного спуска.
	Шаг градиентного спуска с импульсом будет выглядеть следующим обрразом:

  \begin{lstlisting}[language=Python, frame=single]
    def gradient_descent_momentum_step(old, vt, lambd, mu):
      vt_new = mu * vt + lambd * get_gradient(old)
      new = old - vt_new
      return (new, vt_new)
  \end{lstlisting}

  По сравнению с обычным градиентным спуском добавились параметры \verb|vt| -
  значение \verb|v| на $j$-ом шаге и $mu$ - значение $\mu$ из формулы :
  $$v^{j+1}=v^j-\mu\nabla F(x^j)$$

	Шаг для алгоритма Нестерова отличается незначительно:

  \begin{lstlisting}[language=Python, frame=single]
    def gradient_descent_momentum_step(old, vt, lambd, mu):
      vt_new = mu * vt + lambd * get_gradient(old - mu * vt)
      new = old - vt_new
      return (new, vt_new)
  \end{lstlisting}

  \chapter{Параллелизация градиентного спуска}
  Сам по себе градиентный спуск - последовательный алгоритм: шаг за шагом мы
  двигаемся по направлению линий градиента продвигаясь в сторону минимума.
  При этом каждый последующий шаг зависит от предыдущего, что затрудняет
  параллелизацию данного алгоритма. Для задач с большими размерностями
  однопоточных модификаций недостаточно и хотелось бы иметь возможность запускать
  градиентный спуск параллельно. Чтобы достичь этого существуют различные подходы,
  некоторые из которых будут рассмотрены далее.

  \section{Hogwild!}
  Авторы метода \textsc{Hogwild!} предлагают следующий подход к параллелизации:
  запускать стохастический градиентный спуск параллельно без какого-либо
  блокирования. При этом у каждого процесса есть доступ к общей памяти, в которой
  хранится вектор решения $x$. Соответственно каждый процесс может в люой момент
  взять текущее значение $x$ или обновить его. Может возникнуть вопрос: будет ли
  это вообще работать? Не будут ли процессы преписывать прогресс друг друга?
  Как объясняют авторы, если задача, которую мы решаем разряженная, а именно:
  один шаг стохастического градиентного спуска изменяет лишь небольшое количество
  компонент вектора решения. По сути наша задача принимает следующий вид: минимизировать
  функцию $f: X \subseteq \mathbb{R}^n \to \mathbb{R}$ следующего вида
  \begin{equation}
    f(x) = \sum_{e \in E} f_e(x_e)
  \end{equation}

  Здесь $e$ - это некоторое подмножество ${1,2,\ldots ,n}$, а $x_e$ - это те значения
  вектора $x$, координаты которых входят в $e$. В таких задачах перезаписи
  случаются достаточно редко и не дают достаточной ошибки, чтобы алгоритм переставал
  сходиться. Этот метод широко используется в машинном обучении, поскольку многие
  задачи, возникающие в этой области обладают необходимым условием разряженности:
  $n$ - достаточно большое, но каждое конкретное $f_e$, влияет на малое количество
  компонент $x$.

  \section{Hogwild++}
  В идеале скорость работы \textsc{Hogwild!} должна расти при увеличении количества
  процессов, но авторы \textsc{Hogwild++} показывают, что у оригинального алгоритма
  есть следущие проблемы с параллелизацией:
  \begin{itemize}
    \item
    В современных многоядерных системах используются протоколы поддержания
    целостности кэша. Если одно из ядер записывает значение в кэш, все остальные ядра
    должны иметь возможность обратиться к этому обновленному значению. Поэтому,
    когда одно из ядер - \verb|C1| - изменит значение $w$ из общей памяти, оно должно отправить,
    сообщение инвалидирующее копии $w$, хранящиеся в кэше других ядер. И когда ядро \verb|C2|,
    будет обращаться к значению $w$, ему придется получить это значение из \verb|C1| по
    внутренней шине. В случае с многопроцессорной системой все становится еще хуже:
    шины соединяющие процессора значительно медленней и в многопроцессорной системе
    параллельный \textsc{Hogwild!} может работать хуже чем обычный стохастический
    градиентный спуск.
    \item
    Другая проблема - ложные обращения к общей памяти: пусть два ядра модифицируют
    два разных значения $w_{i_1}$ и $w_{i_2}$, и эти значения ледат в памяти рядом,
    а потому лежат в одной кэш-линии. Когда первое ядро \verb|C1|, запишет новое значение
    в $w_{i_1}$, контроллер кэша ядра \verb|C2| инвалидирует кэшированную копию $w_{i_2}$.
    Когда ядру \verb|C2| потребуется доступ к значению $w_{i_2}$ случится кэш-промах
    и придется заново запрашивать это значение, не смотря на то, что $w_{i_2}$ никто
    не менял.
  \end{itemize}
  Решение, предложенное авторами статьи - заменить единую, общую модель $w$ на
  несколько моделей $w_j$, хранящихся в небольших кластерах, состоящих из ядер
  одного процессора. Эти кластеры синхронизируют свои локальные модели при помощи
  децентрализированного протокола с токеном, что уменьшает количество инфраструктурных
  сообщений между процессорами и ядрами. Тесты показывают, что \textsc{Hogwild++}
  обычно работает лучше чем \textsc{Hogwild!}, а в худшем случае показывает такие
  же результаты.

  \section{Асинхронный стохастический градиентный спуск}
  Этот метод решает те же проблемы что и \textsc{Hogwild++}, но другим способом:
  авторы предлагают использовать модель с асинхронной, односторонней коммуникацией,
  в которой процессы, по завершении шага градиентного спуска, посылают свои
  изменения, вне зависимости от статуса получателя. Получатель со своей стороны
  добавляет полученные обновления, когда будет готов. В такой модели нет потерь
  времени на ожидание процессами конца отправки или начала получения обновления.

  В такой модели возникают новые проблемы: могут возникать условия гонок, когда
  два разных источника будут передавать данные одному получателю и в результате
  обновление одного из них будет перезаписано. Но, если мы опять же воспользуемся
  условием разряженности решаемой задачи, такая ситуация не будет возникать достаточно
  часто, чтобы алгоритм перестал работать.

  % \section{SymGD}
  % \section{Our special mix}

  \chapter{Библиотека PETSc}
  \section{PETSc}
  PETSc (Portable Extensible Toolkit for Scientific computation) - набор
  библиотек предназначенных для параллельного решения систем уравнений,
  возникающих при дискретизации уравнений в частных производных, а также для
  поиска решений нелинейных систем обыкновенных дифференциальных уравнений.
  PETSc использует технологию MPI для параллелизации, а также поддерживает
  параллельные вычисления на GPU с использованием CUDA и OpenCL. Основными
  языками для разработки с использованием PETSc являются C, C++.
  Существуют также интерфейсы для разных других языков в том числе Fortran,
  Python, Java, Matlab.

  Преимуществом при использовании PETSc является наличие готовой реализации
  объектов и алгоритмов позволяющих работать с векторами и матрицами параллельно.
  Также плюсом PETSc является модульная система, в которой можно заменять и
  дополнять части библиотеки своими реализациями.

  \section{TAO}
  Одной из библиотек, которые входят в PETSc является TAO. TAO (The Toolkit for
  Advanced Optimization) - библиотека, в которой реализованы алгоритмы для
  решения задач оптимизации.

  Большинство приложений использующих TAO идут по одному и тому же пути: пользователь
  создает объект, отражающий контекст задачи и выбирает алгоритм оптимизации.
  Затем задаёт необходимые для решения задачи функции: целевую функцию, функцию,
  вычисляющую её градиент и Гессиан (матрица, образованная вторыми частными
  производными функции). Затем пользователь включает tao solver (объект который
  является абстракцией алгоритма оптимизации) и после получения результата уничтожает
  созданные объекты.

  Объект tao, являющийся по сути контекстом, содержит в себе метаданные: в нем
  можно задать алгоритм минимизации, задать условие остановки и разные другие
  переменные относящиеся к процессу решения задачи.

  TAO позволяет добавлять свои методы оптимизации. Добавляемый метод должен быть
  написан на C/C++ и содержать некоторый набор функций, описывающих жизненный цикл
  алгоритма оптимизации: создание, уничтожение, настройка, вывод информации для
  пользователя. За это отвечают следующие функции:
  \begin{lstlisting}[language=C, frame=single]
  PetscErrorCode TaoCreate_CG(Tao tao);
  PetscErrorCode TaoDestroy_CG(TAO_SOLVER tao);
  PetscErrorCode TaoSetFromOptions_CG(Tao tao, void *solver);
  PetscErrorCode TaoSetUp_CG(Tao tao);
  PetscErrorCode TaoView_CG(Tao tao, PetscViewer viewer);
  \end{lstlisting}

  Новый метод нужно будет зарегистрировать в PETSc с помощью соответствующей
  процедуры и затем можно будет запускать программы с новым методом, используя
  ключ \verb|-tao_type|. Например:

  \verb|./minsurf2 -tao_type stochastic_gd -tao_cg fr -tao_smonitor|

  Если под названием \verb|stochastic_gd| был зарегистрирован метод стохастического
  градиентного спуска, то эта команда запустит исполняемый файл minsurf2,
  написанный с помощью функций библиотеки PETSc с использованием стохастического
  градиентного спуска в качестве алгоритма минимизации.

  Не смотря на наличие хорошей и подробной документации в PETSc и TAO, та часть
  документации, которая описывает создание собственного метода оптимизации содержит
  довольно много ошибок и неточностей, что создает определенные проблемы при
  написании своей реализации метода оптимизации.

  \chapter*{Заключение}
  \addcontentsline{toc}{chapter}{Заключение}
  {TODO}

  \chapter*{Список литературы}
  \addcontentsline{toc}{chapter}{Список литературы}
  \begin{enumerate}
    \item
    An overview of gradient descent optimization algorithms/
    Sebastian Ruder//
    Insight Centre for Data Analytics, NUI Galway Aylien Ltd., Dublin, 2016 - URL:\\
    http://sebastianruder.com/optimizing-gradient-descent/index.html
    \item
    Gradient descent for machine learning/
    Jason Brownlee//
    March, 2016 - URL:\\
    http://machinelearningmastery.com/gradient-descent-for-machine-learning/
    \item
    Identifying and attacking the saddle point problem in high-dimensional
    non-convex optimization./
    Dauphin Y., Pascanu R., Gulcehre C., Cho K., Ganguli S., and Bengio Y.//
    2014 - URL:\\
    http://arxiv.org/abs/1406.2572
    \item
    Convolutional neural networks for visual recognition/
    Andrej Karpathy//
    Stanford - 2016 - URL:\\
    http://cs231n.github.io/neural-networks-3/
    \item
    Методы оптимизации нейронных сетей/
    Павел Садовников//
    2017 - URL:\\
    https://habrahabr.ru/post/318970/
    \item
    Stochastic gradient descent./
    Wikipedia//
    URL:\\
    https://en.wikipedia.org/wiki/Stochastic\_gradient\_descent
    \item
    Hogwild!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent/
    Feng Niu, Benjamin Recht, Christopher Re and Stephen J. Wright//
    Computer Sciences Department, University of Wisconsin-Madison, June 2011 - URL:\\
    https://people.eecs.berkeley.edu/~brecht/papers/hogwildTR.pdf
    \item
    PETSc Users Manual/
    S. Balay et al.//
    Argonne National Laboratory - April 2016 - URL:\\
    http://www.mcs.anl.gov/petsc/petsc-current/docs/manual.pdf
    \item
    TAO 3.7 Users Manual/
    Todd Munson, Jason Sarich, Sefan Wild, Steven Benson, Lois Curfman McInnes//
    Argonne National Laboratory - April 2017 - URL:\\
    http://www.mcs.anl.gov/petsc/petsc-current/docs/tao\_manual.pdf
    \item
    {TODO: ilya sutskever PhD thesis}
    \item
    {TODO: hogwild++}
    \item
    {TODO: asgd}
  \end{enumerate}

\end{document}
