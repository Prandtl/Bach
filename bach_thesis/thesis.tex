\documentclass[12pt]{report}
\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage{listings}

\textheight 24cm
\voffset -2cm
\textwidth 17cm
\hoffset -1.5cm
\topmargin 0mm

\renewcommand{\bottomfraction}{1.0}
  % Какая часть снизу листа может быть занята картинками
\renewcommand{\textfraction}{0.0}
  % Какая часть листа должна быть занята текстом

\newtheorem{theorem}{Теорема}
\newtheorem{definition}{Определение}
\newtheorem{ex}{Пример}
\newtheorem{tab}{Таблица}
\newtheorem{sat}{Утверждение}


\begin{document}
  \pagestyle{empty} % нумерация выкл.
  \begin{center}
    \small
    МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ ФЕДЕРАЦИИ\\
    Федеральное государственное автономное образовательное учреждение высшего образования\\
    УРАЛЬСКИЙ ФЕДЕРАЛЬНЫЙ УНИВЕРСИТЕТ \\
    имени первого Президента России Б.Н. Ельцина\\
    \vspace{1em}
    ИНСТИТУТ ЕСТЕСТВЕННЫХ НАУК И МАТЕМАТИКИ\\
    Кафедра математической экономики (TODO: Место выполнения ВКР и работы научного руководителя (консультанта) ВКР (либо кафедра, либо департамент))
  \end{center}

  \vspace{1em}

  \begin{center}
    \large
    АДАПТАЦИЯ АЛГОРИТМА ПАРАЛЛЕЛЬНОГО\\ СТОХАСТИЧЕСКОГО ГРАДИЕНТНОГО СПУСКА К ЗАДАЧАМ\\ МЕХАНИКИ СПЛОШНОЙ СРЕДЫ
    \vspace{1em}

    \normalsize
    Направление подготовки 09.03.03 <<Прикладная информатика>>\\
    \vspace{1em}
    Образовательная программа <<TODO: ???>>
    \end{center}
  \vspace{1em}

  \begin{tabular}[t]{@{}l}
    Допустить к защите:\\
    Директор департамента:\\ к.ф.-м.н., доц. М. О. Асанов\\
    \underline{\hspace{5cm}}\\
    \vspace{1em}\\
    Нормоконтроллер:\\ {TODO: find that person's name}\\
    \underline{\hspace{5cm}}
  \end{tabular}
  \hfill
  \begin{tabular}[t]{l@{}}
      Выпускная квалификационная\\работа бакалавра\\
      \textbf{Учанева}\\
      \textbf{Василия Вячеславовича}\\
      \underline{\hspace{5cm}}\\
      \vspace{1em}\\
      Научный руководитель:\\ к.ф.-м.н. В. С. Зверев\\
      \underline{\hspace{5cm}}\\
  \end{tabular}

  \vspace*{\fill}
  \begin{center}
    Екатеринбург 2017 г.
  \end{center}

  \newpage
  \pagestyle{plain} % нумерация вкл.
  \chapter*{Реферат}
  Учанев В. В. - -//- -: стр. - -,

  Ключевые слова: СТОХАСТИЧЕСКИЙ ГРАДИЕНТНЫЙ СПУСК, ПАРАЛЛЕЛИЗАЦИЯ.

  В данной работе рассматривается...{TODO:text}

  \newpage
  \tableofcontents

  \chapter{Введение}
  Оптимизация - поиск наилучшего элемента согласно некоторому критерию,
  например поиск максимального или минимального элемента. Для функции одной
  переменной существует аналитический метод поиска точек экстремума,
  но для функций двух и более переменных используются численные методы.

  Не смотря на то, что математические основы оптимизации были заложены
  в XVIII-XIX веке, широко использоваться они начали во второй половине XX века,
  в связи с появлением и распространением ЭВМ, поскольку использование
  методов оптимизации требует в большинстве случаев большой вычислительной работы.
  Поиск минимального/максимального значения используется во множестве областей:
  в экономике для оптимизации процессов и максимизации прибыли,
  в механике для проектирования и расчетов,
  в социальных науках для моделирования и оптимизации общественных процессов.

  За последние несколько лет был довольно большой скачок в развитии методов
  оптимизации, связанный c развитием машинного обучения. Методы оптимизации
  используются на этапе обучения: параметры модели подбираются так,
  чтобы уменьшить ошибку относительно тренировочного набора данных.

  Одним из наиболее используемых в машинном обучение алгоритмов является
  алгоритм градиентного спуска и его модификации. Причины этому в простоте его
  реализации и скорости работы, которая важна, так как во время обучения
  модель проходит через множество итераций и чем быстрее будет проходить
  каждая итерация, тем быстрее будет процесс поиска оптимальных параметров
  аппроксимирующей модели, то есть  обучение.

  \chapter{Постановка задачи}
  {TODO}

  \chapter{Градиентный спуск}
  \section{Градиентный спуск}

  Градиентный спуск - метод нахождения локального экстремума функции с помощью
  движения по направлению градиента/антиградиента. Это наиболее простой
  в реализации метод среди всех методов локальной оптимизации. Зачастую
  используется как часть других методов оптимизации. Этот метод не решает задачу
  поиска глобального минимума/максимума, то есть нужны модификации для поиска
  глобального экстремума.

  Если нам дана функция $F(x)$ и необходимо найти ее минимум, то шаг градиентного
  спуска выглядит следующим образом:
  \begin{equation}
    x^{j+1}=x^j- \lambda \nabla F(x^j)
  \end{equation}
  где $x^j$- приближение минимума функции на $j$-ом шаге, а $\lambda$ - шаг
  градиентного спуска, который может быть постоянной величиной или вычисляться
  на каждом шаге, например делением каждый раз на некое число, что увеличивает
  вероятность того, что алгоритм сойдется.
  Рассмотрим алгоритм градиентного спуска:
  \begin{enumerate}
    \item
    Задается начальное приближение: $x^0$ и необходимая точность расчета: $\alpha$.
    \item
    Рассчитывается по формуле 3.1 следующее приближение $x^{j+1}$.
    \item
    Проверяются условия остановки, например:
    \begin{enumerate}
      \item
      $|x^{j+1}-x^j| < \alpha$.
      \item
      $\exists i: x_i < x_{i_{min}}$ или $x_i > x_{i_{max}}$, где $x_{i_{min}}$ и $x_{i_{max}}$
      заранее заданые границы для координаты $x_i$.
      \item
      $j>j_max$, где $j_max$ - заранее заданное максимальное число итераций.
    \end{enumerate}
    Если условие остановки выполняется завершаем алгоритм, полученоу $x^j$ - наше найденое решение.
  \end{enumerate}

  \section{Проблемы алгоритма градиентного спуска}
  Градиентный спуск позволяет находить оптимальное решение в простых случаях, но
  в сложных задачах становятся видны следующие проблемы:
  \begin{enumerate}
    \item
    Для оптимальной работы алгоритма выжен правильно выбраный коэффициент $\lambda$
    - величина шага градиетного спуска. При слишком маленьком шаге алгоритм
    сходится слишком долго и может застрять в локальном минимуме, а при слишком
    большом шаге алгоритм будет перескакивать через решение и может расходиться.
    Возможным решением является, например, использование изменяющихся со временем
    значений для шага (т.н. Learning schedules). Но подобное решение будет
    сильно зависеть от данных и его придется адаптировать в каждом конкретном случае.
    \item
    Градиентный спуск застревает в локальных минимумах и в седловых точках.
    При этом седловые точки являются даже большей проблемой, так как чем больше
    размерность пространства в котором мы работаем, тем выше вероятность
    появления седловых точек.
    \item
    Градиентный спуск не оптимизирован для прохождения по оврагам - областям, где
    изменения по одной из компонент намного более крутые чем по другим.
    Градиентный спуск скачет с одной стороны оврага на другую, продвигаясь при
    этом на очень малое расстояние в сторону минимума.
  \end{enumerate}
  Чтобы решить эти проблемы градиентного спуска используются различные модификации,
  некоторые из которых мы рассмотрим далее.

  \section{Стохастический градиентный спуск}
    В стохастическом градиентном спуске, градиент функции в приближенном решении
    аппроксимируется градиентом по одной из компонент, тогда шаг градиентного
    спуска выглядит следующим образом:
    \begin{equation}
      x^{j+1}=x^j- \lambda \nabla F_i(x^j)
    \end{equation}

    Если обычный градиентный спуск на каждом шаге считает градиент полностью, то
    стохасическому градиентному спуску требуется всего одна операция на каждом
    шаге, что значительно увеличивает скорость вычисления на каждом шаге. При
    этом значительно уменьшается точность и функция остановки начинает сильно
    флуктуировать. {TODO: add image}

    Интересной особенностью стохастического градиентного спуска является то, что
    за счет флуктуаций решения, алгоритм способен выходить из локальных минимумов
    и находить решение лучшее, чем обычный градиентный спуск. Проблемой этого
    метода является то, что эти же флуктуации мешают алгоритму попасть в искомую
    точку минимума, поскольку алгоритм постоянно перескакивает через нее.

  \section{Mini-batch gradient descent}
    Этот метод позволяет получить нечто среднее между обычным градиентным спуском
    и стохастическим градиентным спуском. Градиент в точке аппроксимируется
    градиентом по некоторому небольшому количеству компонент. За счет этого мы
    увеличиваем скорость по сравнению с обычным градиетным спуском, а также получаем
    способность выходить из локальных маинимумов, но при этом также уменьшаем
    флуктуации по сравнению со стохастическим градиентным спуском. При использовании
    современных библиотек для матричных операций, скорость обработки каждого
    шага может достигать скорости  работы стохастического градиентного спуска,
    за счет использования векторных расширений процессора.

  \section{Градиентный спуск с импульсом}
    Этот метод заключается в накоплении импульса на каждом шаге. Использование
    импульса позволяет двигаться более уверенно в нужном направлении и уменьшить
    величину осциляций. Формула для шага градиентного спуска изменяется следующим
    образом:
    \begin{equation}
      v^{j} = \mu v^{j-1} + \lambda \nabla F_i(x^j)
    \end{equation}
    \begin{equation}
      x^{j+1} = x^j- v^j
    \end{equation}

    $v^j$ - скользящее среднее шага градиентного спуска, соответственно {TODO}
  \section{Ускоренный градиентный спуск Нестерова}
  \section{Adagrad}
  \section{Adadelta и RMSProp}
  \section{ADAM}

  \chapter{Реализация градиентного спуска на Python}
  Рассмотрим реализацию градиентного спуска на языке Python, с использованием
  библиотеки numpy.

  Шаг градиентного спуска будет выглядеть следующим образом:

  \begin{lstlisting}[language=Python, frame=single]
    def gradient_descent_step(old, lambd):
      new = old - get_gradient(old)*lambd
      return new
  \end{lstlisting}

  Этот метод принимает массив \verb|old| - точку в которой мы находимся и
  \verb|lambd| - параметр который отвечает за величину шага. Здесь и далее метод
  \verb|get_gradient| - метод который позволяет найти значение градиента в точке.

  Используя эту реализацию шага градиентного спуска мы получаем следующую
  реализацию самого градиентного спуска:

  \begin{lstlisting}[language=Python, frame=single]
    x = np.arange(-2, 2, 0.1)
    y = np.arange(-2, 2, 0.1)
    xx, yy = np.meshgrid(x, y)
    xravel = np.ravel(xx)
    yravel = np.ravel(yy)
    points = list(zip(xravel, yravel))
    f, g, a = getTestData(1e-10)
    z = np.array([ f(point) for point in points ])
    zz = z.reshape(xx.shape)
    h = plt.contour(xx, yy, zz, 40)
    old = [1,1]
    delta = 1
    while delta>1e-5:
      new = gradient_descent_step(old, 0.001)
      plt.plot([old[0], new[0]], [old[1], new[1]], 'r-', lw=1)
      old = new
      delta = old - new
  \end{lstlisting}

  Чтобы нарисовать график функции и путь по которму пойдет градиентный спуск
  нужно получить двухмерный массив точек, с которым мы будем оперировать. Метод
  \verb|np.arange(a, b, h)| возвращает вектор элементов от \verb|a| до \verb|b|,
  \verb|с| шагом \verb|h|. Затем метод \verb|np.meshgrid(x, y)| возвращает две
  матрицы \verb|xx, yy|. Строки \verb|xx|, равны вектору \verb|x|, количество
  этих строк равно длине вектора \verb|y|, матрица \verb|yy| получается подобным
  образом. Метод \verb|np.ravel(xx)| преобразовывает матрицу обратно в вектор,
  подставляя друг за другом строки матрицы \verb|xx|. \verb|list(zip(xravel, yravel))|
  возвращает список пар элементов \verb|xravel| и \verb|yravel|. В итоге,
  например если \verb|x = [0, 0.1, … , 1]| и \verb|y = [-1, -0.9, … , 1]|, то
  \verb|points| будет равно
  \begin{center}
    \begin{verbatim}
      [(-1, 0), (-1, 0.1), … ,(-1, 1),
      (-0.9, 0), (-0.9, 0.1), …(-0.9, 1),
      …,
      (1, 0), (1, 0.1), … ,(1, 1)].
    \end{verbatim}
  \end{center}
	Метод \verb|getTestData| возвращает тестовую функцию, а так же функцию для
  получения градиента и антиградиента. Зная нашу тестовую функцию и имея список
  точек можно найти значение функции в каждой точке:
  \verb|np.array([ f(point) for point in points ])|, далее, для удобства, этот
  массив мы преобразуем в матрицу с размерами матрицы \verb|xx|. Далее происходит
  иницализация параметров и мы попадаем в основной цикл: алгоритм будет двигаться
  по градиенту пока величина шага не станет значительно мала, отрисовывая на
  каждом шаге пройденное расстояние.

  Далее будут рассмотрены реализации шага градиентного спуска для разных модификаций,
  реализация градиентного спуска рассматриваться не будет, так как отличается
  лишь в деталях: изменяется количество параметров, которые необходимо
  инициализировать и передать в функцию, совершающую шаг градиентного спуска.
	Шаг градиентного спуска с импульсом будет выглядеть следующим обрразом:

  \begin{lstlisting}[language=Python, frame=single]
    def gradient_descent_momentum_step(old, vt, lambd, mu):
      vt_new = mu * vt + lambd * get_gradient(old)
      new = old - vt_new
      return (new, vt_new)
  \end{lstlisting}

  По сравнению с обычным градиентным спуском добавились параметры \verb|vt| -
  значение \verb|v| на $j$-ом шаге и $mu$ - значение $\mu$ из формулы :
  $$v^{j+1}=v^j-\mu\nabla F(x^j)$$

	Шаг для алгоритма Нестерова отличается незначительно:

  \begin{lstlisting}[language=Python, frame=single]
    def gradient_descent_momentum_step(old, vt, lambd, mu):
      vt_new = mu * vt + lambd * get_gradient(old - mu * vt)
      new = old - vt_new
      return (new, vt_new)
  \end{lstlisting}

  \chapter{Библиотека PETSc}
  \section{PETSc}
  PETSc (Portable Extensible Toolkit for Scientific computation) - набор
  библиотек предназначенных для параллельного решения систем уравнений,
  возникающих при дискретизации уравнений в частных производных, а также для
  поиска решений нелинейных систем обыкновенных дифференциальных уравнений.
  PETSc использует технологию MPI для параллелизации, а также поддерживает
  параллельные вычисления на GPU с использованием CUDA и OpenCL. Основными
  языками для разработки с использованием PETSc являются C, C++.
  Существуют также интерфейсы для разных других языков в том числе Fortran,
  Python, Java, Matlab.

  Преимуществом при использовании PETSc является наличие готовой реализации
  объектов и алгоритмов позволяющих работать с векторами и матрицами параллельно.
  Также плюсом PETSc является модульная система, в которой можно заменять и
  дополнять части библиотеки своими реализациями.

  \section{TAO}
  Одной из библиотек, которые входят в PETSc является TAO. TAO (The Toolkit for
  Advanced Optimization) - библиотека, в которой реализованы алгоритмы для
  решения задач оптимизации.

  Большинство приложений использующих TAO идут по одному и тому же пути: пользователь
  создает объект, отражающий контекст задачи и выбирает алгоритм оптимизации.
  Затем задаёт необходимые для решения задачи функции: целевую функцию, функцию,
  вычисляющую её градиент и Гессиан (матрица, образованная вторыми частными
  производными функции). Затем пользователь включает tao solver (объект который
  является абстракцией алгоритма оптимизации) и после получения результата уничтожает
  созданные объекты.

  Объект tao, являющийся по сути контекстом, содержит в себе метаданные: в нем
  можно задать алгоритм минимизации, задать условие остановки и разные другие
  переменные относящиеся к процессу решения задачи.

  TAO позволяет добавлять свои методы оптимизации. Добавляемый метод должен быть
  написан на C/C++ и содержать некоторый набор функций, описывающих жизненный цикл
  алгоритма оптимизации: создание, уничтожение, настройка, вывод информации для
  пользователя. За это отвечают следующие функции:
  \begin{lstlisting}[language=C, frame=single]
  PetscErrorCode TaoCreate_CG(Tao tao);
  PetscErrorCode TaoDestroy_CG(TAO_SOLVER tao);
  PetscErrorCode TaoSetFromOptions_CG(Tao tao, void *solver);
  PetscErrorCode TaoSetUp_CG(Tao tao);
  PetscErrorCode TaoView_CG(Tao tao, PetscViewer viewer);
  \end{lstlisting}

  Новый метод нужно будет зарегистрировать в PETSc с помощью соответствующей
  процедуры и затем можно будет запускать программы с новым методом, используя
  ключ \verb|-tao_type|. Например:

  \verb|./minsurf2 -tao_type stochastic_gd -tao_cg fr -tao_smonitor|

  Если под названием \verb|stochastic_gd| был зарегистрирован метод стохастического
  градиентного спуска, то эта команда запустит исполняемый файл minsurf2,
  написанный с помощью функций библиотеки PETSc с использованием стохастического
  градиентного спуска в качестве алгоритма минимизации.

  Не смотря на наличие хорошей и подробной документации в PETSc и TAO, та часть
  документации, которая описывает создание собственного метода оптимизации содержит
  довольно много ошибок и неточностей, что создает определенные проблемы при
  написании своей реализации метода оптимизации.

  \chapter{Заключение}
  {TODO}

  \chapter{Список литературы}
  \begin{enumerate}
    \item
    Hogwild!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent/
    Feng Niu, Benjamin Recht, Christopher Re and Stephen J. Wright//
    Computer Sciences Department, University of Wisconsin-Madison, June 2011 - URL:\\
    https://people.eecs.berkeley.edu/~brecht/papers/hogwildTR.pdf
    \item
    An overview of gradient descent optimization algorithms/
    Sebastian Ruder//
    Insight Centre for Data Analytics, NUI Galway Aylien Ltd., Dublin, 2016 - URL:\\
    http://sebastianruder.com/optimizing-gradient-descent/index.html
    \item
    Gradient descent for machine learning/
    Jason Brownlee//
    March, 2016 - URL:\\
    http://machinelearningmastery.com/gradient-descent-for-machine-learning/
    \item
    Identifying and attacking the saddle point problem in high-dimensional
    non-convex optimization./
    Dauphin Y., Pascanu R., Gulcehre C., Cho K., Ganguli S., and Bengio Y.//
    2014 - URL:\\
    http://arxiv.org/abs/1406.2572
    \item
    Convolutional neural networks for visual recognition/
    Andrej Karpathy//
    Stanford - 2016 - URL:\\
    http://cs231n.github.io/neural-networks-3/
    \item
    Методы оптимизации нейронных сетей/
    Павел Садовников//
    2017 - URL:\\
    https://habrahabr.ru/post/318970/
    \item
    Stochastic gradient descent./
    Wikipedia//
    URL:\\
    https://en.wikipedia.org/wiki/Stochastic\_gradient\_descent
    \item
    PETSc Users Manual/
    S. Balay et al.//
    Argonne National Laboratory - April 2016 - URL:\\
    http://www.mcs.anl.gov/petsc/petsc-current/docs/manual.pdf
    \item
    TAO 3.7 Users Manual/
    Todd Munson, Jason Sarich, Sefan Wild, Steven Benson, Lois Curfman McInnes//
    Argonne National Laboratory - April 2017 - URL:\\
    http://www.mcs.anl.gov/petsc/petsc-current/docs/tao\_manual.pdf
  \end{enumerate}

\end{document}
